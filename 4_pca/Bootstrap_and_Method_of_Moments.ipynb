{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Estimation and Method of Moments\n",
    "## DA5400W - Foundations of Machine Learning\n",
    "### Instructor: Dr. Arun B Ayyar\n",
    "### IIT Madras\n",
    "\n",
    "---\n",
    "\n",
    "This notebook covers two important parameter estimation techniques:\n",
    "1. **Method of Moments (MoM)**: A classical parametric approach\n",
    "2. **Bootstrap Estimation**: A modern non-parametric resampling technique\n",
    "\n",
    "Both methods are essential tools in statistical inference and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Method of Moments (MoM)\n",
    "\n",
    "### 1.1 Introduction\n",
    "\n",
    "**Method of Moments** is one of the oldest parameter estimation techniques, dating back to Karl Pearson (1894).\n",
    "\n",
    "**Key Idea:**\n",
    "- Match sample moments (statistics computed from data) with theoretical moments (expectations from the distribution)\n",
    "- Solve the resulting equations to estimate parameters\n",
    "\n",
    "**Steps:**\n",
    "1. Compute sample moments: $m_k = \\frac{1}{n}\\sum_{i=1}^{n} x_i^k$\n",
    "2. Express theoretical moments in terms of parameters: $\\mu_k = E[X^k]$\n",
    "3. Set sample moments equal to theoretical moments: $m_k = \\mu_k$\n",
    "4. Solve for the parameters\n",
    "\n",
    "**Advantages:**\n",
    "- Simple and intuitive\n",
    "- Easy to compute\n",
    "- Works when MLE is difficult\n",
    "\n",
    "**Disadvantages:**\n",
    "- May not be as efficient as MLE\n",
    "- Estimates may not always exist or be unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Example: Exponential Distribution\n",
    "\n",
    "**Problem:** Given data $x_1, x_2, \\ldots, x_n$ from $\\text{Exp}(\\lambda)$, estimate $\\lambda$.\n",
    "\n",
    "**Exponential Distribution:**\n",
    "- PDF: $f(x|\\lambda) = \\lambda e^{-\\lambda x}$ for $x \\geq 0$\n",
    "- Mean: $E[X] = \\frac{1}{\\lambda}$\n",
    "\n",
    "**Method of Moments:**\n",
    "1. First sample moment: $m_1 = \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$\n",
    "2. First theoretical moment: $\\mu_1 = E[X] = \\frac{1}{\\lambda}$\n",
    "3. Set equal: $\\bar{x} = \\frac{1}{\\lambda}$\n",
    "4. Solve: $\\hat{\\lambda}_{MoM} = \\frac{1}{\\bar{x}} = \\frac{n}{\\sum_{i=1}^{n} x_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Exponential Distribution - Method of Moments\n",
    "\n",
    "# True parameter\n",
    "lambda_true = 2.0\n",
    "\n",
    "# Generate sample data\n",
    "n = 100\n",
    "data_exp = np.random.exponential(scale=1/lambda_true, size=n)\n",
    "\n",
    "# Method of Moments estimator\n",
    "lambda_mom = 1 / np.mean(data_exp)\n",
    "\n",
    "print(\"Exponential Distribution - Method of Moments\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True parameter: λ = {lambda_true}\")\n",
    "print(f\"Sample size: n = {n}\")\n",
    "print(f\"Sample mean: {np.mean(data_exp):.4f}\")\n",
    "print(f\"\\nMoM Estimate: λ̂ = {lambda_mom:.4f}\")\n",
    "print(f\"Estimation error: {abs(lambda_mom - lambda_true):.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram with true and estimated distributions\n",
    "axes[0].hist(data_exp, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black', label='Sample data')\n",
    "x_range = np.linspace(0, max(data_exp), 1000)\n",
    "axes[0].plot(x_range, lambda_true * np.exp(-lambda_true * x_range), \n",
    "             'r-', linewidth=2, label=f'True: λ={lambda_true}')\n",
    "axes[0].plot(x_range, lambda_mom * np.exp(-lambda_mom * x_range), \n",
    "             'g--', linewidth=2, label=f'MoM: λ̂={lambda_mom:.3f}')\n",
    "axes[0].set_xlabel('x', fontsize=12)\n",
    "axes[0].set_ylabel('Density', fontsize=12)\n",
    "axes[0].set_title('Exponential Distribution: Data vs Estimated', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Convergence with sample size\n",
    "sample_sizes = np.arange(10, 1000, 10)\n",
    "estimates = []\n",
    "for size in sample_sizes:\n",
    "    sample = np.random.exponential(scale=1/lambda_true, size=size)\n",
    "    estimates.append(1 / np.mean(sample))\n",
    "\n",
    "axes[1].plot(sample_sizes, estimates, 'b-', alpha=0.6, linewidth=1.5, label='MoM estimates')\n",
    "axes[1].axhline(y=lambda_true, color='r', linestyle='--', linewidth=2, label=f'True λ={lambda_true}')\n",
    "axes[1].fill_between(sample_sizes, lambda_true - 0.5, lambda_true + 0.5, \n",
    "                      color='red', alpha=0.1, label='±0.5 band')\n",
    "axes[1].set_xlabel('Sample Size (n)', fontsize=12)\n",
    "axes[1].set_ylabel('Estimated λ', fontsize=12)\n",
    "axes[1].set_title('Convergence of MoM Estimator', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Example: Normal Distribution\n",
    "\n",
    "**Problem:** Given data $x_1, x_2, \\ldots, x_n$ from $N(\\mu, \\sigma^2)$, estimate $\\mu$ and $\\sigma^2$.\n",
    "\n",
    "**Normal Distribution:**\n",
    "- Mean: $E[X] = \\mu$\n",
    "- Variance: $\\text{Var}(X) = E[X^2] - (E[X])^2 = \\sigma^2$\n",
    "\n",
    "**Method of Moments:**\n",
    "1. First moment: $m_1 = \\bar{x} = \\mu$ → $\\hat{\\mu}_{MoM} = \\bar{x}$\n",
    "2. Second moment: $m_2 = \\frac{1}{n}\\sum x_i^2 = \\sigma^2 + \\mu^2$\n",
    "3. Solve: $\\hat{\\sigma}^2_{MoM} = \\frac{1}{n}\\sum (x_i - \\bar{x})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Normal Distribution - Method of Moments\n",
    "\n",
    "# True parameters\n",
    "mu_true = 50\n",
    "sigma_true = 10\n",
    "\n",
    "# Generate sample data\n",
    "n = 200\n",
    "data_normal = np.random.normal(loc=mu_true, scale=sigma_true, size=n)\n",
    "\n",
    "# Method of Moments estimators\n",
    "mu_mom = np.mean(data_normal)\n",
    "sigma2_mom = np.mean((data_normal - mu_mom)**2)  # Biased estimator\n",
    "sigma_mom = np.sqrt(sigma2_mom)\n",
    "\n",
    "print(\"Normal Distribution - Method of Moments\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True parameters: μ = {mu_true}, σ = {sigma_true}\")\n",
    "print(f\"Sample size: n = {n}\")\n",
    "print(f\"\\nMoM Estimates:\")\n",
    "print(f\"  μ̂ = {mu_mom:.4f} (error: {abs(mu_mom - mu_true):.4f})\")\n",
    "print(f\"  σ̂ = {sigma_mom:.4f} (error: {abs(sigma_mom - sigma_true):.4f})\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram with distributions\n",
    "axes[0].hist(data_normal, bins=30, density=True, alpha=0.7, color='lightcoral', edgecolor='black', label='Sample data')\n",
    "x_range = np.linspace(min(data_normal), max(data_normal), 1000)\n",
    "axes[0].plot(x_range, stats.norm.pdf(x_range, mu_true, sigma_true), \n",
    "             'r-', linewidth=2, label=f'True: μ={mu_true}, σ={sigma_true}')\n",
    "axes[0].plot(x_range, stats.norm.pdf(x_range, mu_mom, sigma_mom), \n",
    "             'g--', linewidth=2, label=f'MoM: μ̂={mu_mom:.1f}, σ̂={sigma_mom:.1f}')\n",
    "axes[0].set_xlabel('x', fontsize=12)\n",
    "axes[0].set_ylabel('Density', fontsize=12)\n",
    "axes[0].set_title('Normal Distribution: Data vs Estimated', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(data_normal, dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot: Checking Normality Assumption', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Example: Bernoulli Distribution\n",
    "\n",
    "**Problem:** Given binary data $x_1, x_2, \\ldots, x_n$ from $\\text{Bernoulli}(p)$, estimate $p$.\n",
    "\n",
    "**Bernoulli Distribution:**\n",
    "- PMF: $P(X=x) = p^x(1-p)^{1-x}$ for $x \\in \\{0, 1\\}$\n",
    "- Mean: $E[X] = p$\n",
    "\n",
    "**Method of Moments:**\n",
    "- Set $\\bar{x} = p$\n",
    "- $\\hat{p}_{MoM} = \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$\n",
    "\n",
    "This is also the Maximum Likelihood Estimator (MLE) for the Bernoulli distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Bernoulli Distribution - Method of Moments\n",
    "\n",
    "# True parameter\n",
    "p_true = 0.7\n",
    "\n",
    "# Generate sample data\n",
    "n = 100\n",
    "data_bernoulli = np.random.binomial(1, p_true, size=n)\n",
    "\n",
    "# Method of Moments estimator\n",
    "p_mom = np.mean(data_bernoulli)\n",
    "\n",
    "print(\"Bernoulli Distribution - Method of Moments\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True parameter: p = {p_true}\")\n",
    "print(f\"Sample size: n = {n}\")\n",
    "print(f\"Number of successes: {np.sum(data_bernoulli)}\")\n",
    "print(f\"Number of failures: {n - np.sum(data_bernoulli)}\")\n",
    "print(f\"\\nMoM Estimate: p̂ = {p_mom:.4f}\")\n",
    "print(f\"Estimation error: {abs(p_mom - p_true):.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar plot of outcomes\n",
    "outcomes, counts = np.unique(data_bernoulli, return_counts=True)\n",
    "axes[0].bar(outcomes, counts, color=['coral', 'skyblue'], edgecolor='black', alpha=0.7)\n",
    "axes[0].axhline(y=n*p_true, color='r', linestyle='--', linewidth=2, label=f'Expected successes: {n*p_true:.0f}')\n",
    "axes[0].axhline(y=n*(1-p_true), color='b', linestyle='--', linewidth=2, label=f'Expected failures: {n*(1-p_true):.0f}')\n",
    "axes[0].set_xlabel('Outcome', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('Bernoulli Trials: Observed vs Expected', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['Failure (0)', 'Success (1)'])\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Convergence with sample size\n",
    "sample_sizes = np.arange(10, 2000, 20)\n",
    "estimates = []\n",
    "for size in sample_sizes:\n",
    "    sample = np.random.binomial(1, p_true, size=size)\n",
    "    estimates.append(np.mean(sample))\n",
    "\n",
    "axes[1].plot(sample_sizes, estimates, 'b-', alpha=0.6, linewidth=1.5, label='MoM estimates')\n",
    "axes[1].axhline(y=p_true, color='r', linestyle='--', linewidth=2, label=f'True p={p_true}')\n",
    "axes[1].fill_between(sample_sizes, p_true - 0.1, p_true + 0.1, \n",
    "                      color='red', alpha=0.1, label='±0.1 band')\n",
    "axes[1].set_xlabel('Sample Size (n)', fontsize=12)\n",
    "axes[1].set_ylabel('Estimated p', fontsize=12)\n",
    "axes[1].set_title('Convergence of MoM Estimator', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Bootstrap Estimation\n",
    "\n",
    "### 2.1 Introduction to Bootstrap\n",
    "\n",
    "**Bootstrap** is a powerful resampling technique introduced by Bradley Efron in 1979.\n",
    "\n",
    "**Key Idea:**\n",
    "- Treat the sample as a \"population\"\n",
    "- Resample from it (with replacement) many times\n",
    "- Compute the statistic of interest for each resample\n",
    "- Use the distribution of these statistics to estimate uncertainty\n",
    "\n",
    "**Why Bootstrap?**\n",
    "- **Non-parametric**: No assumptions about the underlying distribution\n",
    "- **Flexible**: Works for any statistic (mean, median, variance, correlation, etc.)\n",
    "- **Practical**: Useful when theoretical formulas are unavailable or complex\n",
    "- **Small samples**: Particularly valuable for small sample sizes\n",
    "\n",
    "**Bootstrap Algorithm:**\n",
    "1. Given original sample: $X_1, X_2, \\ldots, X_n$\n",
    "2. For $b = 1$ to $B$ (number of bootstrap samples):\n",
    "   - Draw $n$ observations **with replacement** from the original sample: $X_1^{*b}, X_2^{*b}, \\ldots, X_n^{*b}$\n",
    "   - Compute the statistic: $\\hat{\\theta}^{*b} = g(X_1^{*b}, X_2^{*b}, \\ldots, X_n^{*b})$\n",
    "3. Use the distribution of $\\{\\hat{\\theta}^{*1}, \\hat{\\theta}^{*2}, \\ldots, \\hat{\\theta}^{*B}\\}$ for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bootstrap Standard Error\n",
    "\n",
    "The **bootstrap standard error** estimates the variability of a statistic.\n",
    "\n",
    "**Formula:**\n",
    "$$\\text{SE}_{boot}(\\hat{\\theta}) = \\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B}(\\hat{\\theta}^{*b} - \\bar{\\theta}^*)^2}$$\n",
    "\n",
    "where $\\bar{\\theta}^* = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{\\theta}^{*b}$\n",
    "\n",
    "**Interpretation:**\n",
    "- This is the standard deviation of the bootstrap distribution\n",
    "- It estimates how much $\\hat{\\theta}$ would vary if we repeated the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Bootstrap Standard Error for the Mean\n",
    "\n",
    "# Original sample\n",
    "np.random.seed(42)\n",
    "original_sample = np.random.normal(loc=100, scale=15, size=50)\n",
    "\n",
    "# Bootstrap parameters\n",
    "B = 10000  # Number of bootstrap samples\n",
    "n = len(original_sample)\n",
    "\n",
    "# Perform bootstrap\n",
    "bootstrap_means = []\n",
    "for b in range(B):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample = np.random.choice(original_sample, size=n, replace=True)\n",
    "    # Compute statistic (mean)\n",
    "    bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "\n",
    "bootstrap_means = np.array(bootstrap_means)\n",
    "\n",
    "# Bootstrap standard error\n",
    "se_boot = np.std(bootstrap_means, ddof=1)\n",
    "\n",
    "# Theoretical standard error (for comparison)\n",
    "se_theory = np.std(original_sample, ddof=1) / np.sqrt(n)\n",
    "\n",
    "print(\"Bootstrap Standard Error Estimation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Original sample size: n = {n}\")\n",
    "print(f\"Original sample mean: {np.mean(original_sample):.4f}\")\n",
    "print(f\"Original sample std: {np.std(original_sample, ddof=1):.4f}\")\n",
    "print(f\"Number of bootstrap samples: B = {B}\")\n",
    "print(f\"\\nBootstrap standard error: {se_boot:.4f}\")\n",
    "print(f\"Theoretical standard error: {se_theory:.4f}\")\n",
    "print(f\"Difference: {abs(se_boot - se_theory):.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bootstrap distribution\n",
    "axes[0].hist(bootstrap_means, bins=50, density=True, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0].axvline(x=np.mean(original_sample), color='r', linestyle='--', linewidth=2, \n",
    "                label=f'Original mean: {np.mean(original_sample):.2f}')\n",
    "axes[0].axvline(x=np.mean(bootstrap_means), color='g', linestyle='--', linewidth=2, \n",
    "                label=f'Bootstrap mean: {np.mean(bootstrap_means):.2f}')\n",
    "# Add normal curve\n",
    "x_range = np.linspace(min(bootstrap_means), max(bootstrap_means), 1000)\n",
    "axes[0].plot(x_range, stats.norm.pdf(x_range, np.mean(bootstrap_means), se_boot), \n",
    "             'orange', linewidth=2, label='Normal approximation')\n",
    "axes[0].set_xlabel('Bootstrap Mean', fontsize=12)\n",
    "axes[0].set_ylabel('Density', fontsize=12)\n",
    "axes[0].set_title(f'Bootstrap Distribution of Sample Mean\\n(B={B} resamples)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot to check normality\n",
    "stats.probplot(bootstrap_means, dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot: Bootstrap Distribution vs Normal', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Bootstrap Confidence Intervals\n",
    "\n",
    "Bootstrap can be used to construct confidence intervals without assuming normality.\n",
    "\n",
    "**Three Common Methods:**\n",
    "\n",
    "1. **Percentile Method** (simplest):\n",
    "   - $(\\alpha/2)$ and $(1-\\alpha/2)$ percentiles of bootstrap distribution\n",
    "   - 95% CI: $[\\hat{\\theta}^*_{0.025}, \\hat{\\theta}^*_{0.975}]$\n",
    "\n",
    "2. **Normal Method**:\n",
    "   - Assumes normality: $\\hat{\\theta} \\pm z_{\\alpha/2} \\cdot SE_{boot}$\n",
    "   - 95% CI: $[\\hat{\\theta} - 1.96 \\cdot SE_{boot}, \\hat{\\theta} + 1.96 \\cdot SE_{boot}]$\n",
    "\n",
    "3. **BCa Method** (Bias-Corrected and Accelerated):\n",
    "   - Most accurate but more complex\n",
    "   - Corrects for bias and skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Bootstrap Confidence Intervals\n",
    "\n",
    "# Using the bootstrap means from previous example\n",
    "alpha = 0.05  # 95% confidence level\n",
    "\n",
    "# Method 1: Percentile method\n",
    "ci_percentile = np.percentile(bootstrap_means, [100*alpha/2, 100*(1-alpha/2)])\n",
    "\n",
    "# Method 2: Normal method\n",
    "z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "ci_normal = [np.mean(original_sample) - z_critical * se_boot,\n",
    "             np.mean(original_sample) + z_critical * se_boot]\n",
    "\n",
    "# Theoretical CI (for comparison)\n",
    "ci_theory = stats.t.interval(1-alpha, df=n-1, loc=np.mean(original_sample), \n",
    "                              scale=se_theory)\n",
    "\n",
    "print(\"Bootstrap Confidence Intervals (95%)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Point estimate: {np.mean(original_sample):.4f}\")\n",
    "print(f\"\\n1. Percentile Method:\")\n",
    "print(f\"   [{ci_percentile[0]:.4f}, {ci_percentile[1]:.4f}]\")\n",
    "print(f\"   Width: {ci_percentile[1] - ci_percentile[0]:.4f}\")\n",
    "print(f\"\\n2. Normal Method:\")\n",
    "print(f\"   [{ci_normal[0]:.4f}, {ci_normal[1]:.4f}]\")\n",
    "print(f\"   Width: {ci_normal[1] - ci_normal[0]:.4f}\")\n",
    "print(f\"\\n3. Theoretical t-interval (for comparison):\")\n",
    "print(f\"   [{ci_theory[0]:.4f}, {ci_theory[1]:.4f}]\")\n",
    "print(f\"   Width: {ci_theory[1] - ci_theory[0]:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.hist(bootstrap_means, bins=50, density=True, alpha=0.5, color='steelblue', edgecolor='black', label='Bootstrap distribution')\n",
    "\n",
    "# Mark the confidence intervals\n",
    "plt.axvline(x=ci_percentile[0], color='red', linestyle='--', linewidth=2, label='Percentile CI')\n",
    "plt.axvline(x=ci_percentile[1], color='red', linestyle='--', linewidth=2)\n",
    "plt.axvspan(ci_percentile[0], ci_percentile[1], alpha=0.2, color='red')\n",
    "\n",
    "plt.axvline(x=ci_normal[0], color='green', linestyle=':', linewidth=2, label='Normal CI')\n",
    "plt.axvline(x=ci_normal[1], color='green', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.axvline(x=np.mean(original_sample), color='blue', linestyle='-', linewidth=3, \n",
    "            label=f'Sample mean: {np.mean(original_sample):.2f}')\n",
    "\n",
    "plt.xlabel('Bootstrap Mean', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title('Bootstrap Confidence Intervals Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Bootstrap for Other Statistics\n",
    "\n",
    "Bootstrap is particularly useful for statistics where theoretical formulas are complex or unavailable.\n",
    "\n",
    "**Examples:**\n",
    "- Median\n",
    "- Correlation coefficient\n",
    "- Ratio of means\n",
    "- Regression coefficients\n",
    "- Machine learning model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Bootstrap for Median\n",
    "\n",
    "# Generate skewed data (median is more robust than mean for skewed data)\n",
    "np.random.seed(123)\n",
    "skewed_data = np.random.exponential(scale=10, size=60)\n",
    "\n",
    "# Bootstrap for median\n",
    "B = 10000\n",
    "n = len(skewed_data)\n",
    "bootstrap_medians = []\n",
    "\n",
    "for b in range(B):\n",
    "    bootstrap_sample = np.random.choice(skewed_data, size=n, replace=True)\n",
    "    bootstrap_medians.append(np.median(bootstrap_sample))\n",
    "\n",
    "bootstrap_medians = np.array(bootstrap_medians)\n",
    "\n",
    "# Bootstrap standard error and CI\n",
    "se_median = np.std(bootstrap_medians, ddof=1)\n",
    "ci_median = np.percentile(bootstrap_medians, [2.5, 97.5])\n",
    "\n",
    "print(\"Bootstrap for Median (Skewed Data)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sample size: n = {n}\")\n",
    "print(f\"Sample mean: {np.mean(skewed_data):.4f}\")\n",
    "print(f\"Sample median: {np.median(skewed_data):.4f}\")\n",
    "print(f\"\\nBootstrap results:\")\n",
    "print(f\"  Bootstrap SE(median): {se_median:.4f}\")\n",
    "print(f\"  95% CI for median: [{ci_median[0]:.4f}, {ci_median[1]:.4f}]\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Original data\n",
    "axes[0].hist(skewed_data, bins=30, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[0].axvline(x=np.mean(skewed_data), color='blue', linestyle='--', linewidth=2, \n",
    "                label=f'Mean: {np.mean(skewed_data):.2f}')\n",
    "axes[0].axvline(x=np.median(skewed_data), color='green', linestyle='--', linewidth=2, \n",
    "                label=f'Median: {np.median(skewed_data):.2f}')\n",
    "axes[0].set_xlabel('Value', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Original Skewed Data', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Bootstrap distribution of median\n",
    "axes[1].hist(bootstrap_medians, bins=50, density=True, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1].axvline(x=np.median(skewed_data), color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Sample median: {np.median(skewed_data):.2f}')\n",
    "axes[1].axvline(x=ci_median[0], color='orange', linestyle=':', linewidth=2, label='95% CI')\n",
    "axes[1].axvline(x=ci_median[1], color='orange', linestyle=':', linewidth=2)\n",
    "axes[1].axvspan(ci_median[0], ci_median[1], alpha=0.2, color='orange')\n",
    "axes[1].set_xlabel('Bootstrap Median', fontsize=12)\n",
    "axes[1].set_ylabel('Density', fontsize=12)\n",
    "axes[1].set_title(f'Bootstrap Distribution of Median (B={B})', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Bootstrap for Correlation Coefficient\n",
    "\n",
    "# Generate correlated data\n",
    "np.random.seed(456)\n",
    "n = 50\n",
    "x = np.random.normal(0, 1, n)\n",
    "y = 0.7 * x + np.random.normal(0, 0.5, n)  # Correlation ≈ 0.7\n",
    "\n",
    "# Original correlation\n",
    "corr_original = np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "# Bootstrap for correlation\n",
    "B = 10000\n",
    "bootstrap_corrs = []\n",
    "\n",
    "for b in range(B):\n",
    "    # Resample pairs (important!)\n",
    "    indices = np.random.choice(n, size=n, replace=True)\n",
    "    x_boot = x[indices]\n",
    "    y_boot = y[indices]\n",
    "    bootstrap_corrs.append(np.corrcoef(x_boot, y_boot)[0, 1])\n",
    "\n",
    "bootstrap_corrs = np.array(bootstrap_corrs)\n",
    "\n",
    "# Bootstrap SE and CI\n",
    "se_corr = np.std(bootstrap_corrs, ddof=1)\n",
    "ci_corr = np.percentile(bootstrap_corrs, [2.5, 97.5])\n",
    "\n",
    "print(\"Bootstrap for Correlation Coefficient\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sample size: n = {n}\")\n",
    "print(f\"Sample correlation: r = {corr_original:.4f}\")\n",
    "print(f\"\\nBootstrap results:\")\n",
    "print(f\"  Bootstrap SE(r): {se_corr:.4f}\")\n",
    "print(f\"  95% CI for r: [{ci_corr[0]:.4f}, {ci_corr[1]:.4f}]\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(x, y, alpha=0.6, color='steelblue', edgecolor='black')\n",
    "# Add regression line\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "axes[0].plot(x, p(x), \"r--\", linewidth=2, label=f'r = {corr_original:.3f}')\n",
    "axes[0].set_xlabel('X', fontsize=12)\n",
    "axes[0].set_ylabel('Y', fontsize=12)\n",
    "axes[0].set_title('Original Data: X vs Y', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bootstrap distribution of correlation\n",
    "axes[1].hist(bootstrap_corrs, bins=50, density=True, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[1].axvline(x=corr_original, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Sample r: {corr_original:.3f}')\n",
    "axes[1].axvline(x=ci_corr[0], color='orange', linestyle=':', linewidth=2, label='95% CI')\n",
    "axes[1].axvline(x=ci_corr[1], color='orange', linestyle=':', linewidth=2)\n",
    "axes[1].axvspan(ci_corr[0], ci_corr[1], alpha=0.2, color='orange')\n",
    "axes[1].set_xlabel('Bootstrap Correlation', fontsize=12)\n",
    "axes[1].set_ylabel('Density', fontsize=12)\n",
    "axes[1].set_title(f'Bootstrap Distribution of Correlation (B={B})', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Comparing Bootstrap with Theoretical Results\n",
    "\n",
    "Let's compare bootstrap with theoretical results for a case where we know the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison: Bootstrap vs Theory for Sample Mean\n",
    "\n",
    "# Simulation parameters\n",
    "true_mu = 50\n",
    "true_sigma = 10\n",
    "sample_size = 30\n",
    "n_simulations = 1000\n",
    "B = 5000\n",
    "\n",
    "# Storage\n",
    "coverage_theory = 0\n",
    "coverage_bootstrap = 0\n",
    "widths_theory = []\n",
    "widths_bootstrap = []\n",
    "\n",
    "np.random.seed(789)\n",
    "\n",
    "for sim in range(n_simulations):\n",
    "    # Generate sample\n",
    "    sample = np.random.normal(true_mu, true_sigma, sample_size)\n",
    "    \n",
    "    # Theoretical CI\n",
    "    se_theory = np.std(sample, ddof=1) / np.sqrt(sample_size)\n",
    "    ci_theory = stats.t.interval(0.95, df=sample_size-1, loc=np.mean(sample), scale=se_theory)\n",
    "    widths_theory.append(ci_theory[1] - ci_theory[0])\n",
    "    if ci_theory[0] <= true_mu <= ci_theory[1]:\n",
    "        coverage_theory += 1\n",
    "    \n",
    "    # Bootstrap CI\n",
    "    bootstrap_means = []\n",
    "    for b in range(B):\n",
    "        boot_sample = np.random.choice(sample, size=sample_size, replace=True)\n",
    "        bootstrap_means.append(np.mean(boot_sample))\n",
    "    ci_boot = np.percentile(bootstrap_means, [2.5, 97.5])\n",
    "    widths_bootstrap.append(ci_boot[1] - ci_boot[0])\n",
    "    if ci_boot[0] <= true_mu <= ci_boot[1]:\n",
    "        coverage_bootstrap += 1\n",
    "\n",
    "# Results\n",
    "print(\"Bootstrap vs Theoretical Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True parameters: μ = {true_mu}, σ = {true_sigma}\")\n",
    "print(f\"Sample size: n = {sample_size}\")\n",
    "print(f\"Number of simulations: {n_simulations}\")\n",
    "print(f\"Bootstrap resamples per simulation: B = {B}\")\n",
    "print(f\"\\nCoverage (should be ≈95%):\")\n",
    "print(f\"  Theoretical t-interval: {coverage_theory/n_simulations*100:.2f}%\")\n",
    "print(f\"  Bootstrap percentile: {coverage_bootstrap/n_simulations*100:.2f}%\")\n",
    "print(f\"\\nAverage CI width:\")\n",
    "print(f\"  Theoretical: {np.mean(widths_theory):.4f}\")\n",
    "print(f\"  Bootstrap: {np.mean(widths_bootstrap):.4f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.hist(widths_theory, bins=30, alpha=0.5, color='blue', edgecolor='black', label='Theoretical CI widths')\n",
    "plt.hist(widths_bootstrap, bins=30, alpha=0.5, color='red', edgecolor='black', label='Bootstrap CI widths')\n",
    "plt.axvline(x=np.mean(widths_theory), color='blue', linestyle='--', linewidth=2, \n",
    "            label=f'Mean (Theory): {np.mean(widths_theory):.2f}')\n",
    "plt.axvline(x=np.mean(widths_bootstrap), color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Mean (Bootstrap): {np.mean(widths_bootstrap):.2f}')\n",
    "plt.xlabel('CI Width', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title(f'Confidence Interval Widths: Bootstrap vs Theory\\n({n_simulations} simulations)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Comparison and Summary\n",
    "\n",
    "### 3.1 Method of Moments vs Bootstrap\n",
    "\n",
    "| Aspect | Method of Moments | Bootstrap |\n",
    "|--------|-------------------|----------|\n",
    "| **Type** | Parametric | Non-parametric |\n",
    "| **Assumptions** | Requires distributional form | No distributional assumptions |\n",
    "| **Purpose** | Point estimation of parameters | Uncertainty quantification (SE, CI) |\n",
    "| **Computation** | Analytical (usually simple) | Computational (intensive) |\n",
    "| **Sample Size** | Works for any size | Better with larger samples |\n",
    "| **Flexibility** | Limited to moments | Works for any statistic |\n",
    "| **Efficiency** | May not be optimal | Approaches optimal with large B |\n",
    "\n",
    "### 3.2 When to Use Each Method\n",
    "\n",
    "**Use Method of Moments when:**\n",
    "- You know the distributional family (e.g., Normal, Exponential)\n",
    "- You need quick point estimates\n",
    "- Moments are easy to compute\n",
    "- MLE is difficult or intractable\n",
    "\n",
    "**Use Bootstrap when:**\n",
    "- You need standard errors or confidence intervals\n",
    "- The statistic is complex (median, correlation, etc.)\n",
    "- You don't want to assume a distribution\n",
    "- Theoretical formulas are unavailable\n",
    "- Sample size is small to moderate\n",
    "\n",
    "### 3.3 Key Takeaways\n",
    "\n",
    "1. **Method of Moments** provides simple parameter estimates by matching sample and theoretical moments\n",
    "2. **Bootstrap** is a powerful resampling technique for estimating uncertainty without distributional assumptions\n",
    "3. Both methods are complementary: MoM for point estimation, Bootstrap for inference\n",
    "4. Bootstrap is particularly valuable in machine learning for model evaluation and uncertainty quantification\n",
    "5. Always check assumptions and validate results when possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Practice Exercises\n",
    "\n",
    "Try these exercises to reinforce your understanding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Method of Moments for Uniform Distribution\n",
    "# Given data from Uniform(0, θ), estimate θ using MoM\n",
    "# Hint: E[X] = θ/2, so θ̂ = 2*mean(X)\n",
    "\n",
    "# Generate data\n",
    "theta_true = 10\n",
    "data_uniform = np.random.uniform(0, theta_true, size=100)\n",
    "\n",
    "# Your code here:\n",
    "# theta_mom = ...\n",
    "\n",
    "print(\"Exercise 1: Uniform Distribution MoM\")\n",
    "print(f\"True θ: {theta_true}\")\n",
    "# print(f\"MoM estimate: {theta_mom:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Bootstrap for Standard Deviation\n",
    "# Compute bootstrap SE and 95% CI for the standard deviation\n",
    "\n",
    "# Generate data\n",
    "data_ex2 = np.random.normal(100, 15, size=50)\n",
    "\n",
    "# Your code here:\n",
    "# B = 10000\n",
    "# bootstrap_stds = []\n",
    "# for b in range(B):\n",
    "#     ...\n",
    "\n",
    "print(\"Exercise 2: Bootstrap for Standard Deviation\")\n",
    "print(f\"Sample std: {np.std(data_ex2, ddof=1):.4f}\")\n",
    "# print(f\"Bootstrap SE: ...\")\n",
    "# print(f\"95% CI: [...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Compare MoM and MLE for Exponential Distribution\n",
    "# Compute both estimates and compare\n",
    "# MLE for Exponential: λ̂_MLE = n / Σxᵢ (same as MoM!)\n",
    "\n",
    "# Generate data\n",
    "lambda_true_ex3 = 1.5\n",
    "data_ex3 = np.random.exponential(scale=1/lambda_true_ex3, size=200)\n",
    "\n",
    "# Your code here:\n",
    "# lambda_mom = ...\n",
    "# lambda_mle = ...\n",
    "\n",
    "print(\"Exercise 3: MoM vs MLE for Exponential\")\n",
    "print(f\"True λ: {lambda_true_ex3}\")\n",
    "# print(f\"MoM: {lambda_mom:.4f}\")\n",
    "# print(f\"MLE: {lambda_mle:.4f}\")\n",
    "# print(f\"Are they the same? {np.isclose(lambda_mom, lambda_mle)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
